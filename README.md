# U-Net with MobileNetV2 Encoder for Image Segmentation

This repository implements an image segmentation pipeline using **U-Net** with a **MobileNetV2 encoder** pretrained on ImageNet.  
The model is designed for binary semantic segmentation tasks (e.g., foregroundâ€“background separation such as butterflies vs. background).

---

## ğŸš€ Features
- **Preprocessing & Data Loading**:
  - Resizes training/test images and masks to `512x512`.
  - Combines multiple instance masks into a single binary mask.
  - Preserves original test image sizes for prediction resizing.

- **Model Architecture**:
  - U-Net decoder built on top of a pretrained **MobileNetV2** encoder.
  - Skip connections for multi-scale feature fusion.
  - Final sigmoid output for binary masks.

- **Training**:
  - Dice coefficient + Binary Cross-Entropy (BCE) combined loss.
  - Training with encoder frozen, followed by fine-tuning (unfreezing all layers).
  - Uses callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard.

- **Evaluation & Prediction**:
  - Train/validation split (90/10).
  - Sanity check plots for images, masks, and predictions.
  - Saves test predictions resized back to their **original dimensions**.

---

## ğŸ“‚ Project Structure
ğŸ“Š Dataset Format
Training data (/mask-trin-path/)

Each sample is in its own folder:
â”œâ”€â”€ main.py # Main script (training + prediction pipeline)
â”œâ”€â”€ logs/ # TensorBoard logs
â”œâ”€â”€ model_for_butterfly_unet.h5 # Saved trained model (created after training)
â”œâ”€â”€ mask-output-path-/ # Predicted segmentation masks for test data
â”œâ”€â”€ /mask-trin-path/ # Training dataset (images + masks)
â””â”€â”€ /test-path/ # Test dataset (images only)

---

## ğŸ›  Requirements
Install dependencies via pip:

```bash
pip install tensorflow numpy scikit-image matplotlib tqdm
ğŸ“Š Dataset Format
Training data (/mask-trin-path/)

Each sample is in its own folder:
train_id/
 â”œâ”€â”€ images/
 â”‚    â””â”€â”€ train_id.png
 â””â”€â”€ masks/
      â”œâ”€â”€ mask1.png
      â”œâ”€â”€ mask2.png
      â””â”€â”€ ...
Test data (/test-path/)

Each test sample folder contains only an image:
test_id/
 â””â”€â”€ images/
      â””â”€â”€ test_id.png
ğŸƒ Usage

1- Prepare your dataset in the structure described above.

2- Run the script to train and predict:
   python main.py
3- After training:

   -Best model saved as model_for_butterfly_unet.h5.

   -Predictions saved in mask-output-path-/test_id/test_id_pred.png.

ğŸ“ˆ Example Outputs

During training and validation, sanity check plots are displayed:

Train Image

Ground Truth Mask

Predicted Mask

At inference, binary masks are saved for each test image.
